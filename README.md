# AI智能告警分析系统 🚀

[![Spring Boot](https://img.shields.io/badge/Spring%20Boot-3.5.5-brightgreen.svg)](https://spring.io/projects/spring-boot)
[![Spring AI](https://img.shields.io/badge/Spring%20AI-1.0.0-blue.svg)](https://spring.io/projects/spring-ai)
[![Java](https://img.shields.io/badge/Java-17-orange.svg)](https://openjdk.java.net/projects/jdk/17/)
[![Redis](https://img.shields.io/badge/Redis-Latest-red.svg)](https://redis.io/)

## 📋 系统概述

**AI智能告警分析系统**是一个基于Spring AI框架构建的智能运维平台，专注于ELK运维告警的智能分析与处理。系统集成了多个大模型，提供实时的告警分析、根因推断和处理建议，大幅提升运维效率。

### 🎯 核心功能

#### 🔥 智能告警分析
- **多模型支持**: 集成阿里云千问和腾讯混元双模型，支持动态切换
- **智能分类**: 自动识别告警类型（网络超时、系统错误、服务调用失败等）
- **优先级判断**: 基于错误码自动判断告警级别（严重/高/中/低/信息）
- **根因分析**: 结合知识库和历史案例，智能推断故障根本原因

#### 🧠 RAG增强检索
- **双重RAG支持**: 阿里云百炼RAG + 本地向量存储
- **知识库管理**: 自动加载错误码映射和故障处理经验
- **语义检索**: 基于向量相似性的智能知识检索
- **实时更新**: 支持知识库的动态更新和去重处理

#### 💾 对话记忆系统
- **持久化存储**: 基于Redis的分布式对话记忆
- **会话隔离**: 支持多用户、多会话的独立记忆管理
- **窗口化管理**: 智能控制对话历史长度，避免上下文过载

#### 🛠️ 工具集成
- **系统健康检查**: 实时监控服务器状态、网络连通性
- **错误码查询**: 智能解析和查询错误码详细信息
- **时间工具**: 提供准确的时间信息支持
- **扩展性**: 支持自定义工具的快速集成

#### 📊 监控与缓存
- **性能监控**: 集成Micrometer，统计处理性能和成功率
- **多层缓存**: 针对不同业务场景的差异化缓存策略
- **实时指标**: 告警处理量、RAG查询性能等关键指标

### 🏗️ 系统架构

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   前端界面      │    │   API网关       │    │   负载均衡      │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                       │
         └───────────────────────┼───────────────────────┘
                                 │
┌─────────────────────────────────────────────────────────────────┐
│                    AI智能告警分析系统                            │
├─────────────────┬─────────────────┬─────────────────────────────┤
│  告警分析服务   │   对话记忆      │        工具集成             │
│  - 预处理       │   - Redis存储   │        - 健康检查           │
│  - 分类判断     │   - 会话隔离    │        - 错误码查询         │
│  - 优先级       │   - 窗口管理    │        - 系统监控           │
└─────────────────┴─────────────────┴─────────────────────────────┘
         │                       │                       │
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   大模型层      │    │   知识库层      │    │   存储层        │
│  - 阿里云千问   │    │  - 百炼RAG      │    │  - Redis        │
│  - 腾讯混元     │    │  - 向量数据库   │    │  - 缓存系统     │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

### 🚀 快速开始

#### 环境要求
- Java 17+
- Redis 6.0+
- Maven 3.6+

#### 配置说明
```properties
# 阿里云百炼配置
spring.ai.dashscope.api-key=your-dashscope-key
spring.ai.dashscope.chat.options.model=qwen-plus

# 腾讯混元配置  
spring.ai.hunyuan.secret-id=your-secret-id
spring.ai.hunyuan.secret-key=your-secret-key

# Redis配置
spring.data.redis.host=192.168.41.129
spring.data.redis.port=6379
spring.data.redis.password=123456
```

#### 启动步骤
1. **克隆项目**
   ```bash
   git clone https://github.com/your-repo/spring_ai_ops_assistant.git
   cd spring_ai_ops_assistant
   ```

2. **配置环境**
   - 修改 `application.properties` 中的API密钥和Redis配置
   - 确保Redis服务正常运行

3. **启动应用**
   ```bash
   mvn spring-boot:run
   ```

4. **测试接口**
   ```bash
   curl -X POST http://localhost:8100/sendMsg \
   -H "Content-Type: application/json" \
   -d '{
     "msg": "[告警]错误码=1621346903&目的Server=ao_vb_base_account_server",
     "modelType": "qwen",
     "sessionId": "test_session",
     "enableRAG": true,
     "enableMemory": true
   }'
   ```

### 📡 API接口

#### 告警分析接口
- **URL**: `POST /sendMsg`
- **功能**: 智能分析告警信息，提供根因分析和处理建议

**请求参数**:
```json
{
  "msg": "告警内容",
  "modelType": "qwen|hunyuan", 
  "sessionId": "会话ID",
  "userId": "用户ID",
  "enableRAG": true,
  "enableMemory": true
}
```

**响应格式**: 流式SSE响应，实时返回分析结果

### 🔧 技术栈详情

| 组件 | 版本 | 说明 |
|------|------|------|
| Spring Boot | 3.5.5 | 核心框架 |
| Spring AI | 1.0.0 | AI集成框架 |
| Redis | Latest | 缓存和向量存储 |
| 阿里云百炼 | - | 千问模型和RAG |
| 腾讯混元 | - | 备用大模型 |
| Micrometer | - | 监控指标 |

### 📈 性能指标

| 指标 | 目标值 | 说明 |
|------|--------|------|
| 响应时间 | < 3秒 | 告警分析平均响应时间 |
| 并发处理 | 100+ | 同时处理的告警数量 |
| 准确率 | > 85% | 告警分析准确率 |
| 可用性 | 99.9% | 系统可用性目标 |

---

## 📚 Spring AI 核心知识点笔记

### 1. SSE（服务器发送事件）
#### 1.1 流式输出（Response Stream）
- **定义**：大模型生成结果时，逐步返回内容，分批实时传输给客户端的输出方式
- **应用场景**：大模型响应较慢的场景（如长文本生成、复杂问题推理）
- **Spring AI 用法**：通过`ChatModel`和`ChatClient`组件实现

#### 1.2 SSE 核心概念
- **定义**：服务端通过单向HTTP连接，持续向客户端发送数据片段（逐句/逐词）的技术
- **核心流程**：
  1. 客户端发起HTTP请求
  2. 服务端保持连接不关闭
  3. 有新数据时，通过该连接实时推送给客户端
- **应用场景**：
  - 实时通知：股票行情、新闻推送、系统告警
  - 协作应用：用户在线状态展示
  - 状态更新：文件上传进度、后台任务处理状态

#### 1.3 SSE 与 WebSocket 的区别（补充常见对比）
| 特性                | SSE（服务器发送事件）| WebSocket                  |
|---------------------|-----------------------------|---------------------------|
| 连接方向            | 单向（服务端→客户端）| 双向（客户端↔服务端）|
| 通信协议            | HTTP协议（基于现有HTTP）| 独立的WebSocket协议       |
| 数据格式            | 仅支持文本（UTF-8）| 支持文本+二进制数据       |
| 兼容性              | 大部分现代浏览器支持（需polyfill兼容旧版） | 兼容性稍差（部分老旧环境不支持） |
| 使用复杂度          | 低（无需额外依赖，原生HTTP） | 高（需专门的服务端/客户端实现） |
| 适用场景            | 单向实时推送（如告警、通知） | 双向实时交互（如聊天、游戏） |

---

### 2. Prompt 提示词
- **定义**：引导AI模型生成特定输出的输入格式与指令
- **Prompt 四大角色（核心）**：
  1. **System（系统角色）**：设定AI的边界、角色、定位，指导AI的行为逻辑
  2. **User（用户角色）**：用户的原始提问，是AI的输入问题
  3. **Assistant（助手角色）**：AI返回的响应信息，用于对话记忆、历史回答积累
  4. **Tool（工具角色）**：桥接外部服务，支持函数调用/工具调用能力
- **提示词模板**：可通过Spring AI的模板引擎（如FreeMarker、Mustache）定义标准化Prompt模板，提升提示词复用性

---

### 3. 格式化输出
- **定义**：将AI返回的自然语言答案，自动映射到指定的Java对象（POJO）中
- **应用场景**：
  - 识别用户输入的地址、手机号、姓名等信息，自动填充到对应字段
  - 运维告警分析中，将AI输出的告警类型、影响范围、解决方案映射到结构化对象

---

### 4. ChatMemory 对话记忆
**作用**：保存用户与AI的历史对话记录，使AI具备多轮对话能力
**存储方式（按场景选择）**：
1. **内存存储**：基于`ChatMemory`实现，轻量但重启后丢失（适合测试/临时场景）
2. **持久化存储**：`RedisChatMemory`（基于Redis，适合生产环境）
3. **窗口化存储**：`MessageWindowChatMemory`（只保留最近N轮对话，避免历史记录过多）

---

### 5. 向量化与向量数据库
#### 5.1 核心概念
- **向量**：具有大小和方向的量，在AI中表现为浮点型数组
- **文本向量化**：将文本、图像、视频等非结构化数据转换为高维浮点型向量的过程

#### 5.2 向量数据库
- **核心功能**：
  1. 存储文本/图像/视频转换后的向量（`VectorStore`组件）
  2. 支持**相似性搜索**（而非关系型数据库的精准匹配）
  3. 给定一个向量，返回语义相似的向量集合
- **核心特点**：
  1. 捕捉复杂的词汇语义关系（同义词、多义词的语义相似性）
  2. 为检索增强生成（RAG）提供核心支持
- **通俗理解**：将文本映射到高维空间的点，语义相似的文本在空间中的距离更近（如「麦当劳」和「肯德基」的向量距离，比「肯德基」和「大盘鸡」更近）

---

### 6. RAG 检索增强生成
- **定义**：通过「先检索外部知识，再生成回答」的机制，补充AI的知识盲区，提升回答准确性
- **核心流程**：
  1. **索引阶段**：将外部知识库（如运维文档、错误码说明）转换为向量，存储到向量数据库
  2. **检索阶段**：用户提问后，将问题向量化，从向量数据库中检索语义相似的知识片段
  3. **生成阶段**：将问题+检索到的知识片段作为Prompt，交给大模型生成回答

#### 6.1 项目实践：AI智能运维助手的RAG实现
- **技术组合**：阿里云百炼嵌入模型（text-embedding-v3） + Spring AI + 向量数据库RedisStack + DeepSeek大模型
- **实现步骤**：
  1. 定义错误码及模块信息（可存储在本地或阿里云百炼知识库）
  2. 执行知识库脚本，将文档内容读取→向量化→写入RedisStack（支持去重）
  3. 运维告警提问时，检索RedisStack中的相关知识，增强大模型回答

---

### 7. Tool Calling 工具调用
- **定义**：将外部工具类/API与大模型无缝衔接，让AI具备调用外部服务的能力（类似开发中的utils工具类）
- **应用场景**：
  1. 访问实时数据（如查询运维监控平台的CPU使用率、磁盘容量）
  2. 执行特定工具类逻辑（如调用ELK API查询告警日志、发送钉钉通知）
- **工作流程**（以查天气为例）：
  1. AI判断用户问题是否需要调用工具
  2. 调用对应的工具API获取数据
  3. 将工具返回的结果与问题结合，生成最终回答
- **实践步骤**：
  1. 定义Tools工具类（如ELK日志查询工具、钉钉通知工具）
  2. 在Spring AI中注册工具类
  3. 配置大模型的工具调用规则

---

### 8. MCP 服务
- **定义**：用于大模型之间的通讯协议，类比微服务之间的调用机制，实现大模型的协同工作
- **自定义MCP**：可基于Spring AI开发自定义MCP服务，适配业务场景
- **在线MCP服务**：mcp.so（可直接接入使用）
- **架构模式**：
  1. **STDIO**：标准输入输出模式（同步单次交互）
  2. **SSE**：流式输出模式（异步实时推送）
- **模式区别**：STDIO适用于简单的单次请求响应，SSE适用于需要实时返回的长任务场景

---

## 🤝 贡献指南

欢迎提交Issue和Pull Request来改进项目！

## 📄 许可证

本项目采用 MIT 许可证 - 查看 [LICENSE](LICENSE) 文件了解详情。

## 📞 联系方式

- 项目维护者: 阿栋-EdonShen
- 邮箱：478483056@qq.com
- 项目地址：[GitHub Repository URL]
